---
title: "Tag 6 - Metadaten modellieren und Schnittstellen nutzen"
date: 2021-12-02
---

**Salü liebes Tagebuch**,

wir sehen uns heute und morgen gleich nochmals um noch den Ersatztermin nachzuholen, mach dich also bereit für eine Ladung neue Informationen.
Das Hauptthema dieses Eintrages werden **Metadaten** sein. Um wieder einmal auf die **Übersicht im Schaubild** zu kommen,

![image](https://user-images.githubusercontent.com/90834675/151672983-7dc0deb3-10cd-480b-bd20-d5e482cd127e.png)

 
Wir haben jetzt bereits **Koha** sowie **ArchivesSpace** installiert und **DSpace** in der Demoversion genutzt. Bei allen dreien haben wir eine **OAI-PMH-Schnittstelle** wie auch im Schaubild darauf hingewiesen wird. Bei DSpace haben wir das dann doch etwas anders gemacht, die Grafik ist jedoch nicht angepasst, man könnte aber sagen das wir das manuell gemacht haben. Nun haben wir die Daten vorliegend in Dublin Core und müssten die anderen beiden noch herunterladen. Um dann den nächsten Schritt machen zu können, nämlich die Daten ins gleiche Format zubekommen, **MARC21-XML**. Es würde auch ein anderes Format gehen, wie Dublin Core, wichtig ist einfach das es einheitlich ist um es in den Suchindex einzuspielen.

Bei den Austauschprotokollen für Metadaten haben wir bereits von der **Z39.50** gehört, welche von der Library of Congress stammt. Es gibt aber natürlich auch noch andere wie die **SRU**, welche der direkte Nachfolger der Z39.50 ist, oder eben die [**OAI-PMH**](https://www.openarchives.org/pmh/) welche wir verwenden. OAI-PMH ist vor allem für grosse Datenmengen geeignet.

Um diese Datenmengen zu „harvesten“ benutzen wir die OAI-PMH-Schnittstelle und das Tool [**VuFindHarvest**](https://github.com/vufind-org/vufindharvest). Wir benutzen dieses Tool da **VuFind** in dem wir zuletzt alles vereinen wollen zum gleichen Projekt gehören. Interessant fand ich dabei die Note das VuFind auch ein auf der Suchmaschine Solr basierendes Discovery-System wie Primo ist. Durch das sehe ich jetzt auch den Zusammenhang besser wieso es in swisscovery, auch Publikationen wie Artikel und andere Open Access Sachen anzeigt, weil ich jetzt davon ausgehe, dass das dort auch alles so zusammengeführt wird. Diese Erkenntnisse zu gewinnen, wenn man einmal sieht wie das ganze zusammenhängt, finde ich sehr wertvoll, vor allem es nicht nur irgendwo zu lesen oder als Randnotiz, sondern es selber zu machen und zu sehen und es somit auf einer anderen Ebene zu verstehen.

Ebenfalls haben wir **XSLT Crosswalks** kurz angeschaut. Was sind Crosswalks, fragst du dich jetzt liebes Tagebuch, das ist der gebräuchliche Begriff, um die Konvertierung von einem Metadatenstandard in einen anderen zu beschreiben. Konkret heisst das beispielsweise von Dublin Core zu MARC21. Der Crosswalk beinhaltete Regeln wie Werte und Elemente zugeordnet werden sollen, das sogenannte **Mapping**. Idealerweise wäre das verlustfrei, jedoch ist meist keine 1:1-Zuordnung möglich. **XSLT** beschreibt dabei die Programmiersprache zur Transformation von XML-Dokumenten. Einen guten Einstieg kann man sich mit dieser [Literaturempfehlung](https://programminghistorian.org/en/lessons/transforming-xml-with-xsl) holen. 
Wenn man öfters solche Dokumente über XSL ins XML überführen möchten würde, wäre es von Vorteil sich da vertieft einzulesen, dafür reicht die Zeit im Modul jedoch nicht. Um doch ein grundsätzliches Verständnis davon zu haben, haben wir uns im Unterricht ein Beispiel dazu angesehen.

![image](https://user-images.githubusercontent.com/90834675/151673205-d132700c-8fd7-4536-a13d-4d19f79818b2.png)

 
Anhand dieses Beispiel, sieht man eine **XML-Datei** und wie solche Regeln aufgebaut sind in XSL. In der ersten Zeile des Bildausschnitts sieht man xsl:template, was die Vorlage bezeichnet, und das match=“/metadata“ bedeutet das die nachfolgenden Regeln für alle Elemente aus der XML-Datei die in Metadata stehen, angewendet werden. Für unsere Crosswalks nutzen wir MarcEdit 7, welches wir auch auf die virtuellen Maschinen installiert haben, und machen das nicht selber von Hand.

Das wäre dann auch schon der erste Teil den wir zum Thema Metadaten modellieren gemacht haben, also bis bald liebes Tagebuch,
Joy
